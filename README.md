# Enhanced Applicability of Reinforcement Learning-Based Energy Management for Hybrid Powertrain Systems
Deep reinforcement learning (DRL) algorithms play a vital force in promoting the intelligent development of control strategies. This paper proposes a DRL-based hybrid powertrain energy management strategy for enhanced adaptability including a novel training idea and a training scheme, and provides public benchmark models and comparison results for subsequent work. Firstly, the flaws of the traditional reward function commonly used in the past are discussed in detail, such as the misleading of the SOC deviation and the troublesome adjustment of weights, and the novel unweighted reward is designed. By combining the rule-based engine start-stop strategy, it achieves more convenient training. Secondly, because unfamiliar state vectors may appear at any time in the online testing, resulting in suboptimal or even dangerous control of DRL agents, a novel training scheme with a concept of state-based driving cycles. According to the “question bank”-style training scenario, the DRL agent can master a richer state space as possible during the offline training. Moreover, for generating a state-based featured driving cycle, CARLA, DBNet, Gran Turismo, and one standard driving cycle WLTC are used. Finally, to solve the lack of benchmark models and comparison results, the standard DRL algorithm and the hybrid powertrain of MathWorks are adopted to complete co-simulation training on the Tencent cloud server. Furthermore, the hardware-in-the-loop online testing driven by a human driver is implemented to verify the optimization and real-time performance, and the powertrain models, data, and final results have been made public, and the testing video has been uploaded.

Part of the powertrain models, data, and results are public to https://github.com/KaysenC/Enhanced-Applicability-of-RL-Based-Energy-Management-for-Hybrid-Powertrain-Systems, and the video of the HIL testing is uploaded https://www.youtube.com/watch?v=-3YOtBiqigU&t=9s for verification.

![sjiojfewagoegjfi](https://github.com/KaysenC/Enhanced-Applicability-of-RL-Based-Energy-Management-for-Hybrid-Powertrain-Systems/assets/68646204/0aacaf60-5354-4bec-a8d4-c5867ed3906b)
(a) The HIL platform
![HIL platform](https://github.com/KaysenC/Enhanced-Applicability-of-RL-Based-Energy-Management-for-Hybrid-Powertrain-Systems/assets/68646204/6f05eb81-8566-4909-b647-23279607235c)
(b) The HIL connection
Fig. Hardware-in-the-loop experiment.

Once the paper is accepted, more data will be uploaded and public. Furthermore, if you have any questions, please contact email: 20220701066@stu.cqu.edu.cn
